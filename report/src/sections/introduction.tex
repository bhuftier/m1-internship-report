\section{Introduction}

$\NP$-hard problems are widely recognized as unsolvable in polynomial time unless $\P = \NP$. However, not only do most scientists believe that $\P \neq \NP$, but conjectures such as the Exponential Time Hypothesis (ETH) \cite{impagliazzo2001complexity} offer little hope for discovering even subexponential time algorithms for some of these $\NP$-hard problems. This is one of the main reason why we study parameterized complexity.

% (maybe remove this part
% Parameterized complexity aims to classify computational problems according to their inherent difficulty with respect to multiple input parameters. The complexity of a problem is then evaluated as a function of these parameters.
% )
Formally, a parameterized problem is defined as a language $L \subseteq \Sigma^* \times \N$, and a parameterized class $\CC{C}$ is described by a function $f_{\CC{C}} : \N \times \N \mapsto \N$. We say that $L \in \CC{C}$ if there exists an algorithm that decides whether $(x, k) \in L$ in time $f_{\CC{C}}(|x|, k)$. Of course, we would prefer to find functions that are not exponential in $n = |x|$. Thus, we will focus on the class of parameterized problems that can be solved in $f(k)\cdot n^{\O(1)}$ time, for any function $f$. This class is called \textit{Fixable Parameter Tractable} (\CC{FPT}).

\medskip

But let's drive into a concrete problem to fully understand what we are talking about. Let's recall the \prob{VertexCover} problem:

\begin{problem}
    \problemtitle{VertexCover}
    \probleminput{A graph $G = (V, E)$, an integer $k$}
    \problemquestion{Is there $X \subseteq V$ such that $|X| \leq k$ and $X$ is a vertex cover of $G$, i.e. $\forall \{x, y\} \in E, X \cap \{x, y\} \neq \emptyset$?}
\end{problem}

Observe that given a subset $X \subseteq V$, we can check in polynomial time if $|X| \leq k$ and if $X$ is a vertex cover of $G$. Thus, we can trivially answer the question in time $\O(2^n \cdot n^{\O(1)})$, where $n = |V|$, by testing every subset $X \subseteq V$. This complexity can be improved to $\O(\varphi^n \cdot n^{O(1)})$, where $\varphi \approx 1.618$ is the golden ratio, by observing two things: firstly, we can consider that every vertex has at least one neighbour, or we can remove it from the graph without changing the best vertex cover; secondly, for every vertex $x$, if $x$ is not in the vertex cover of $G$, then every neighbour of $x$ needs to be in the vertex cover. These observations lead to the following recurrence: $T(n) \leq T(n - 1) + T(n - 2)$; wheter we take $x$ (and we remove $x$ from the graph), or we don't take $x$ and instead take all its neighbours (and we remove $x$ and all its neighbours from the graph). We can recognise the Fibonacci sequence which gives us our time complexity.

\medskip

But can we refine our algorithm by introducing a parameter? Let's start with the integer $k$ given in the input. Observe that in the recursion tree given in the previous paragraph, we take at least one vertex at each step to include it in the vertex cover. Since the vertex cover cannot exceed $k$, it implies that the depth of the recursion tree cannot exceed $k$. Therefore, we have a $\O(2^k \cdot n^{\O(1)})$ algorithm for \prob{VertexCover}, parameterized by $k$. Note that this algorithm places \prob{VertexCover} parameterized by $k$ in \CC{FPT} with $f(k) = 2^k$.

While we will not go into the details of the techniques used, it is known that \prob{VertexCover} can be solved in time $\O(1.2738^k + n\cdot k)$ using kernelization and branching techniques \cite{chen2006improved}, which completly outperforms the $\O(\varphi^n \cdot n^{\O(1)})$ algorithm since $k \leq n$.

\medskip

Let's explore another parameter: the \textit{treewidth} of $G$. We will define more precisely the treewidth of a graph in the next Section, but for now, you can think of it as a measure of how similar the graph is to a tree. It is known that \prob{VertexCover} can be solved in time $\O(2^{\tw}\cdot\tw^{\O(1)}\cdot n)$, where $\tw$ denotes the treewidth of $G$, using dynamic programming techniques \cite[Corollary~7.6]{cygan2015parameterized}. Interestingly, it is also known that even though the dynamic programming techniques used in \cite[Corollary~7.6]{cygan2015parameterized} are one of the most basic approaches in parameterized techniques, we cannot expect a better algorithm for \prob{VertexCover} parameterized by \tw{} unless the \textit{Strong Exponential Time Hypothesis} (SETH) fails \cite{lokshtanov2011known}. In other words, for every $\varepsilon > 0$, we do not expect any algorithm in time $\O((2-\varepsilon)^\tw \cdot n^{\O(1)})$ or it would imply that SETH is wrong.

\medskip

This lower bound on treewidth raises interesting questions: given that $\tw{} \leq n$ and there exists an algorithm with time complexity $\O(\varphi^n \cdot n^{\O(1)})$ but no algorithm with $\O((2 - \varepsilon)^\tw  \cdot n^{\O(1)})$, is there an intermediate parameter $p$ such that $\tw \leq p \leq n$ for which we can find an algorithm with time complexity $\O((2 - \varepsilon)^p \cdot n^{\O(1)})$ for any $\varepsilon > 0$?  Conversely, is there a parameter $p$ within the same range where it is impossible to achieve such an algorithm under SETH?

It appears that for many problems and parameters, the dynamic programming approach is often tight, and we cannot expect a better time algorithm under SETH. The focus during this internship was to refine our understanding of the lower and upper bounds for these problems and parameters.
% Replace this sentences by a plan of the report
In this report, we will begin by compiling a bibliography detailing known lower and upper bounds for a hierarchy of parameters and various \NP-hard problems. Then we will try to refine our understanding of closing the gap between these bounds. Finally, we will provide some insights into the ideas used to derive these bounds.